# Bayesian machine Learning
Lecturer: RÃ©mi Bardenet

## Evaluation
Two grades: one practical and one project around a research paper.

## Lectures
### Lecture 1
* Annotated slides are [here](https://nextcloud.univ-lille.fr/index.php/s/ds5SdFWnTrEM3b6)
* You can go through all problems in Section 1 of the exercise sheet except 1.4. See also the additional exercises on posterior derivations listed from other books.
* The main reference that I used for this lecture is Chapters 7 and 8 of [(Parmigiani and Inoue, 2009)](https://www.webdepot.umontreal.ca/Usagers/perronf/MonDepotPublic/stt2100/Decision_theory.pdf).
* You can also check Chapter 5 of [(Murphy, 2012)](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwiQ6NDzhuXsAhVPLBoKHRQ3AvUQFjAAegQIBxAC&url=https%3A%2F%2Fdoc.lagout.org%2Fscience%2FArtificial%2520Intelligence%2FMachine%2520learning%2FMachine%2520Learning_%2520A%2520Probabilistic%2520Perspective%2520%255BMurphy%25202012-08-24%255D.pdf&usg=AOvVaw3X0sY_qZRP7o5WDlWa5X8V).
### Lecture 2
* Annotated slides TBC.
* You can now go through all problems in the exercise sheet, up to 2.2. A link to the corresponding book for the James-Stein estimator is [here](http://library.lol/main/A82270D055F6EE991539AC0533036E0D).