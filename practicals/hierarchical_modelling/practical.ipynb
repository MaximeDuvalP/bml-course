{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the notebook reloads the module each time we modify it\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# make sure the displays are nice\n",
    "%matplotlib inline\n",
    "#figsize(12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hierarchical_modelling as hm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "import numpy as np\n",
    "import numpy.linalg as npl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical \\#2: using a hierarchical model to predict GDP as a function of ruggedness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This practical will be marked and has to be done individually. **Deadline is 2 December, 23:59**. Please email me a zip file containing \n",
    "* this Jupyter notebook, containing your answers. Answer each question immediately below the corresponding question. An answer consists in a few sentences in plain English in a Markdown cell, with a snippet of code in a code cell if necessary.\n",
    "* an html version of the same notebook with all cells executed.\n",
    "* the companion Python file, that you will have filled. I should be able to run your notebook with the Python file placed in the same folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I prepared a class that fetches data for you\n",
    "PM = hm.PracticalMaterial()\n",
    "X, y = PM.fetch_data()\n",
    "\n",
    "# Let us plot data\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=True)\n",
    "\n",
    "sns.scatterplot(X[\"rest\"], y[\"rest\"], ax=ax[1])\n",
    "ax[0].set(xlabel=\"Ruggedness index\", ylabel=\"log GDP\", title=\"Non-African nations\")\n",
    "\n",
    "sns.scatterplot(X[\"African\"], y[\"African\"], ax=ax[0])\n",
    "ax[1].set(xlabel=\"Ruggedness index\", ylabel=\"log GDP\", title=\"African nations\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same geographer as for Practical \\#1 comes back to you. She has a new hypothesis: GDP only increases with ruggedness for African nations. We have the same 170 points, with $y_i$ the log GDP, and $x_i$ the ruggedness index, for $i=1,\\dots,170$. But now we also have a new binary variable $z_i\\in\\{0,1\\}$, $i=1,\\dots,170$, that indicates whether the corresponding country is in Africa. \n",
    "\n",
    "## Writing down a probabilistic model\n",
    "\n",
    "We stick with linear regression given how small the dataset is. But we need a model where we can formalize the geographer's question, and compare the slope of the regressed line for African nations to the slope corresponding to the rest of the nations. In particular, let $N^{(k)}$, $k\\in\\{\\text{\"African\"}, \\text{\"rest\"}\\}$ be the number of African and non-African nations in the dataset. Let $(X^{(k)}_i, y^{(k)}_i)_{i=1,\\dots,N^{(k)}}$ be the corresponding $N^{(k)}$ data points, for $k\\in\\{\\text{\"African\"}, \\text{\"rest\"}\\}$.\n",
    "\n",
    "We consider the two likelihoods\n",
    "$$ \n",
    "p(\\mathbf y^{(k)} \\vert X^{(k)}, \\mu^{(k)}, \\beta^{(k)}, \\sigma^{(k)}) = \\prod_{i=1}^{N^{(k)}} \\mathcal{N}\\left(y_i^{(k)}\\vert \\mu^{(k)}+ \\beta^{(k)} X^{(k)}_i, (\\sigma^{(k)})^2\\right), \\quad k\\in\\{\\text{\"African\"}, \\text{\"rest\"}\\}.\n",
    "$$\n",
    "\n",
    "**Question:** Let $k\\in\\{\\text{\"African\"}, \\text{\"rest\"}\\}$. Assume that the features are normalized, in the sense that $\\sum_{i=1}^{N^{(k)}} X^{(k)}_i = 0$. Let us put an improper prior $p(\\mu^{(k)})\\propto 1$ on the intercept $\\mu^{(k)}$. Show that we can integrate $\\mu^{(k)}$ out, so that\n",
    "$$\n",
    "p(\\mathbf y^{(k)} \\vert X^{(k)},\\beta^{(k)}, \\sigma^{(k)}) = \\int p(\\mathbf y^{(k)},\\mu^{(k)} \\vert X^{(k)},\\beta^{(k)}, \\sigma^{(k)}) \\mathrm{d}\\mu^{(k)} = \\prod_{i=1}^{N^{(k)}} \\mathcal{N}\\left(y_i^{(k)}- m^{(k)}\\vert \\beta^{(k)} X^{(k)}_i, (\\sigma^{(k)})^2\\right), \\quad k\\in\\{\\text{\"African\"}, \\text{\"rest\"}\\},\n",
    "$$\n",
    "where $m^{(k)} = \\frac{1}{N^{(k)}}\\sum_{i=1}^{N^{(k)}} y^{(k)}_i$ denotes the within-class average label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** TBC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Henceforth, we will assume that data is normalized, so that $\\sum_{i=1}^{N^{(k)}} X^{(k)}_i = 0$ and $m^{(k)}=0$, for $k\\in\\{\\text{\"African\"}, \\text{\"rest\"}\\}$. We thus need to include this preprocessing in our code, and I did it for your in the method `GibbsSampler.load_and_normalize_data()` of the class `GibbsSampler`, which we we shall meet shortly. Before that, we need to finish specifying our prior over the remaining variables $\\beta^{(k)},\\sigma^{(k)}$. In order to apply Gibbs sampling, we need the conditionals to express in closed form. We thus look for a conjugate prior for linear regression: the normal-inverse Gamma prior. I recommend that you pause and read Sections 7.6.1-7.6.3 of Murphy to get familiar with this prior. \n",
    "\n",
    "With Murphy's notation, we let\n",
    "$$ \n",
    "\\beta^{(k)}, \\sigma^{(k)} \\vert \\overline{\\beta} \\sim \\mathcal{N}-\\mathcal{IG}(\\overline{\\beta}, V=1, a=1, b=1), \\quad k\\in\\{\\text{\"African\"}, \\text{\"rest\"}\\}. \n",
    "$$\n",
    "\n",
    "Note how the only unknown parameter of this prior (a ``hyperparameter\") is $\\overline{\\beta}$, and that this parameter is common to both classes $k\\in\\{\\text{\"African\"}, \\text{\"rest\"}\\}$. Thus, $\\beta^{(\\text{\"African\"})}$ and $\\beta^{(\\text{\"rest\"})}$ are not independent under the prior. We hope that this dependence will regularize the estimates of the individual slopes, forbidding them to be too different. This is particularly useful when you have a small dataset, or if you hope that there is something to learn from the data in the other class. \n",
    "\n",
    "**Question:** We need to choose a prior over $\\overline{\\beta}$. What can we choose if we want the conditional \n",
    "$$\n",
    "\\overline{\\beta}\\vert \\beta^{(\\text{\"African\"})}, \\beta^{(\\text{\"rest\"})}\n",
    "$$\n",
    "to be easy to sample? *Hint: think ``conjugate prior\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** TBC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have specified a full joint model, with posterior\n",
    "$$\n",
    "p(\\beta^{(\\text{\"African\"})}, \\beta^{(\\text{\"rest\"})}, \\sigma^{(\\text{\"African\"})}, \\sigma^{(\\text{\"rest\"})}, \\overline{\\beta}\\vert \\mathbf y, X) \\propto\n",
    "p\\left(\\mathbf y^{(\\text{\"African\"})}\\vert  X^{(\\text{\"African\"})}, \\beta^{(\\text{\"African\"})}, \\sigma^{(\\text{\"African\"})}\\right) \n",
    "\\times p\\left(\\mathbf y^{(\\text{\"rest\"})}\\vert X^{(\\text{\"rest\"})}, \\beta^{(\\text{\"rest\"})}, \\sigma^{(\\text{\"rest\"})}\\right) \n",
    "\\times p(\\beta^{(\\text{\"African\"})}, \\sigma^{(\\text{\"African\"})} \\vert \\overline{\\beta})\n",
    "\\times p(\\beta^{(\\text{\"rest\"})}, \\sigma^{(\\text{\"rest\"})} \\vert \\overline{\\beta})\n",
    "\\times p(\\overline{\\beta}) \\qquad (*)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Assuming you can compute any integral with respect to this joint law, how would you answer the geographer's question? What integral should be our goal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** TBC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a Gibbs sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sample from the posterior (*) over our five parameters, we propose to use Gibbs sampling. First, given the conditional structure of our model (feel free to write the graphical model for extra points), we have\n",
    "$$\n",
    "p(\\overline{\\beta}\\vert \\text{other variables}) = p(\\overline{\\beta}\\vert\\beta^{(\\text{\"African\"})}, \\beta^{(\\text{\"rest\"})}, \\sigma^{(\\text{\"African\"})}, \\sigma^{(\\text{\"rest\"})}) = \\text{TBC}.\n",
    "$$ \n",
    "\n",
    "**Question:** Complete the calculation.\n",
    "\n",
    "Second, for $k\\in\\{\\text{\"African\"}, \\text{\"rest\"}\\}$, it comes\n",
    "$$ \n",
    "p(\\beta^{(k)}, \\sigma^{(k)}\\vert \\text{other variables}) = p(\\beta^{(k)}, \\sigma^{(k)}\\vert X^{(k)}, \\mathbf{y}^{(k)}, \\overline{\\beta}) = \\text{TBC}.\n",
    "$$\n",
    "**Question:** Complete the calculation. *Hint: Read Murphy's Section 7.6.3 again*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to implement our Gibbs sampler. Check out the `GibbsSampler` class in the companion Python file? You should make the following cell run correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gibbs = hm.GibbsSampler(num_full_sweeps=1000)\n",
    "gibbs.load_and_normalize_data()\n",
    "gibbs.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've made a small function to plot the MCMC traces and visually check that they mix properly, i.e. that the time series do not exhibit any strong \"non-independent\" behaviour, like linear trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gibbs.plot_traces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO visualize the posterior, we can also look at the pairwise scatterplots of our posterior sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gibbs.plot_pairwise_marginals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Now that we have a posterior sample, what do we answer the geographer, who wanted to test whether GDP increased with ruggedness in African nations, and decreased with ruggedness in other places? Is your decision sensitive to the choices we made for the priors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** TBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Now the geographer is asking you to predict the GDP of a non-African nation that was not in the original dataset, with ruggedness index $4$. What can you tell her?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** TBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus question:** Implement the same model in `PyMC3`, change the priors, run Hamiltonian MC instead of Gibbs and check that the geographer's decision is robust to changing the functional form of the priors for nonconjugate ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
